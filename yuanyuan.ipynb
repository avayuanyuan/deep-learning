{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "filename = \"MNISTdata.hdf5\"\n",
    "myfile = h5py.File(filename, 'r') \n",
    "X_train=np.array(myfile[\"x_train\"])\n",
    "X_train = X_train.reshape((X_train.shape[0],28,28))\n",
    "Y_train=np.array(myfile['y_train'])\n",
    "X_test=np.array(myfile['x_test'])\n",
    "X_test = X_test.reshape((X_test.shape[0],28,28))\n",
    "Y_test=np.array(myfile['y_test'])\n",
    "myfile.close()\n",
    "Y_train_1=Y_train.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 60000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_one_hot_matrix(labels):\n",
    "    labels=labels.flatten()\n",
    "    c=int(max(labels)+1)\n",
    "    b=labels.shape[0]\n",
    "    a=np.zeros((c,b))\n",
    "    a[labels,np.arange(b)]=1.\n",
    "    return a\n",
    "Y_train=convert_one_hot_matrix(Y_train)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "class convolution_net:\n",
    "    def __init__(self,fw,fh,N_filter,X_train,Y_train):\n",
    "        self.N_filter=N_filter\n",
    "        self.fh=fh\n",
    "        self.fw=fw\n",
    "        self.Wc=np.random.randn(self.fh,self.fw,self.N_filter)*0.01\n",
    "        self.dWc=np.zeros((self.fh,self.fw,self.N_filter))\n",
    "        _,self.Nh,self.Nw=X_train.shape\n",
    "        self.n_H=self.Nh-self.fh+1\n",
    "        self.n_W=self.Nw-self.fw+1\n",
    "        \n",
    "        self.W1=0.01*np.random.randn(10,self.n_H*self.n_W*self.N_filter)\n",
    "        self.dW1=np.zeros((10,self.n_H*self.n_W*self.N_filter))\n",
    "        self.b1=0.01*np.random.randn(10,1)\n",
    "        self.db1=np.zeros((10,1))\n",
    "        #self.b2=np.zeros((10,1))\n",
    "        #self.db2=np.zeros((10,1))\n",
    "        self.X=X_train\n",
    "        self.Y=Y_train\n",
    "        self.costs = []\n",
    "        \n",
    "    \n",
    "    \n",
    "    def convolve(self,X,K):\n",
    "        dim1 = X.shape[0]-K.shape[0]+1\n",
    "        dim2 = X.shape[1]-K.shape[1]+1\n",
    "        iters = product(range(dim1),range(dim2))\n",
    "        results = np.zeros((dim1,dim2))\n",
    "        for i,j in iters:\n",
    "            results[i,j] = np.sum(X[i:i+K.shape[0],j:j+K.shape[1]]*K[:,:])\n",
    "        return results\n",
    "    \n",
    "    def forward_propagation(self,X_train):\n",
    "        self.m=X_train.shape[0]\n",
    "        self.Z_out=np.zeros((self.m,self.n_H,self.n_W,self.N_filter))\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.N_filter):\n",
    "                self.Z_out[i,:,:,j]=self.convolve(X_train[i,:,:],self.Wc[:,:,j])\n",
    "        A_0=np.where(self.Z_out>0, self.Z_out,0)\n",
    "        self.A_0=A_0.reshape((self.m, self.n_H*self.n_W*self.N_filter))\n",
    "        Z_1=np.dot(self.W1,self.A_0.T)+self.b1\n",
    "        #self.A_1=np.where(Z_1>0,Z_1,0.)\n",
    "        #Z_2=np.dot(self.W2,self.A_1)+self.b2\n",
    "        self.A_1=np.exp(Z_1)/np.sum(np.exp(Z_1),axis=0,keepdims=True)\n",
    "        assert self.A_1.shape==(10,self.m)\n",
    "        return self.A_1\n",
    "    \n",
    "    def compute_cost(self,Y_train):\n",
    "        cost=-1./self.m*np.sum(Y_train*np.log(self.A_1))\n",
    "        assert (Y_train.shape[0] == self.A_1.shape[0])\n",
    "        return cost\n",
    "    \n",
    "    def backward_propagation(self,Y_train,X_train):\n",
    "        dZ_1=self.A_1-Y_train\n",
    "        #self.dW2 = np.dot(dZ_2,self.A_1.T)\n",
    "        #self.db2= np.sum(dZ_2,axis=1,keepdims=True)\n",
    "        #dA_prev = np.dot(self.W2.T,dZ_2)\n",
    "        #dZ_1=np.where(self.A_1> 0, 1., 0.)*dA_prev\n",
    "        self.dW1 = np.dot(dZ_1,self.A_0)\n",
    "        self.db1 = np.sum(dZ_1,axis=1,keepdims=True)\n",
    "        dA_0=np.dot(self.W1.T,dZ_1).T\n",
    "        dA_0=dA_0.reshape((self.m,self.n_H,self.n_W,self.N_filter))\n",
    "        self.A_0=self.A_0.reshape((self.m,self.n_H,self.n_W,self.N_filter))\n",
    "        dZ_out=np.where(self.A_0> 0, 1., 0.)*dA_0\n",
    "        dWc = np.zeros((self.m,self.fh,self.fw,self.N_filter))\n",
    "        for i in range(self.m):  \n",
    "            a_prev_pad=X_train[i,:,:]             \n",
    "            for j in range(self.N_filter):           \n",
    "                    dWc[i,:,:,j] = self.convolve(a_prev_pad,dZ_out[i,:,:,j])\n",
    "                    # self.dbc[:,:,j] += np.sum(dZ_out[i,:,:,j])\n",
    "        self.dWc = np.sum(dWc, axis=0)\n",
    "        return 1\n",
    "    \n",
    "    def update_parameters(self,learning_rate):\n",
    "        self.W1= self.W1-learning_rate*self.dW1\n",
    "        self.b1= self.b1-learning_rate*self.db1\n",
    "        #self.W2= self.W2-learning_rate*self.dW2\n",
    "        #self.b2= self.b2-learning_rate*self.db2\n",
    "        self.Wc=self.Wc-learning_rate*self.dWc\n",
    "        #self.bc=self.bc-learning_rate*self.dbc\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:]\n",
    "    shuffled_Y = Y[:,permutation].reshape((10,m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    index_array=[i*mini_batch_size for i in range(num_complete_minibatches)]\n",
    "    index_array.append(m)\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[index_array[k]:index_array[k+1],:,:]\n",
    "        mini_batch_Y = shuffled_Y[:,index_array[k]:index_array[k+1]]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize(X_train,Y_train):\n",
    "    \n",
    "    mynet=convolution_net(4,4,3,X_train, Y_train)\n",
    "    return mynet\n",
    "\n",
    "def train(network,learning_rate = 0.001,\n",
    "          num_epochs = 20, mini_batch_size = 256, print_cost = True):\n",
    "    # Optimization loop\n",
    "    X_train = network.X\n",
    "    Y_train = network.Y\n",
    "    minibatches = random_mini_batches(X_train, Y_train, mini_batch_size)\n",
    "    for i in range(num_epochs): \n",
    "        #alpha=1./np.sqrt(num_epochs)*learning_rate\n",
    "        cost=0\n",
    "        for minibatch in minibatches:\n",
    "\n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "            # Forward propagation\n",
    "            a3= mynet.forward_propagation(minibatch_X)\n",
    "\n",
    "            # Compute cost\n",
    "            cost += mynet.compute_cost(minibatch_Y)/len(minibatches)\n",
    "\n",
    "            # Backward propagation\n",
    "            mynet.backward_propagation(minibatch_Y,minibatch_X)\n",
    "            \n",
    "            mynet.update_parameters(learning_rate)\n",
    "        mynet.costs.append(cost)\n",
    "        if print_cost and (i % 2 == 0 or i==num_epochs-1):\n",
    "            print (\"Cost after epoch %i: %f\" %(i, cost))\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(mynet.costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 10)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return mynet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mynet = initialize(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.466694\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-148271c9e7b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmynet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_batch_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-63b52a32a010>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, learning_rate, num_epochs, mini_batch_size, print_cost)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0ma3\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmynet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Compute cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-39b925c7d010>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(self, X_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mA_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ_out\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_H\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_W\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-39b925c7d010>\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(self, X, K)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   1930\u001b[0m                           initial=initial)\n\u001b[1;32m   1931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(mynet, print_cost = True,num_epochs=10,mini_batch_size =60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n",
      "test accuracy: 97.16%\n"
     ]
    }
   ],
   "source": [
    "mypredict_test = mynet.forward_propagation(X_test)\n",
    "mypredict_test = np.argmax(mypredict_test.T,axis=1)\n",
    "print (mypredict_test)\n",
    "accu = np.sum(1.*(mypredict_test == Y_test.flatten()) )/mypredict_test.shape[0]\n",
    "print (\"test accuracy: \"+str(accu*100.0)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 4 ... 5 6 8]\n",
      "train accuracy: 98.06%\n"
     ]
    }
   ],
   "source": [
    "mypredict_train = mynet.forward_propagation(X_train)\n",
    "mypredict_train = np.argmax(mypredict_train.T,axis=1)\n",
    "print (mypredict_train)\n",
    "accu = np.sum(1.*(mypredict_train == Y_train_1) )/mypredict_train.shape[0]\n",
    "print(\"train accuracy: \"+str(accu*100.0)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
